{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befd2867-c79a-4a07-b5e9-02da778d9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy import VideoFileClip\n",
    "import os\n",
    "\n",
    "def cut_highlight(video_path, highlights, output_dir=\"highlights\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    clips = []\n",
    "    for idx, highlight in enumerate(highlights):\n",
    "        try:\n",
    "            clip = VideoFileClip(video_path).subclip(highlight['start'], highlight['end'])\n",
    "\n",
    "            # ‚ö° Make it vertical (crop center)\n",
    "            if clip.w > clip.h:  # if horizontal\n",
    "                clip = clip.crop(\n",
    "                    width=clip.h * 9/16,  # make it 9:16\n",
    "                    height=clip.h,\n",
    "                    x_center=clip.w/2,\n",
    "                    y_center=clip.h/2\n",
    "                )\n",
    "\n",
    "            # Resize to full vertical HD (1080x1920)\n",
    "            clip = clip.resize(height=1920, width=1080)\n",
    "\n",
    "            output_path = os.path.join(output_dir, f\"highlight_{idx+1}.mp4\")\n",
    "            clip.write_videofile(output_path, codec=\"libx264\")\n",
    "            clips.append(output_path)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Clip creation failed: {e}\")\n",
    "    return clips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336fe8f0-4399-447a-bf72-8653f626e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "\n",
    "def download_video(video_url, output_path=\"video.mp4\"):\n",
    "    yt = YouTube(video_url)\n",
    "    stream = yt.streams.filter(progressive=True, file_extension=\"mp4\").order_by('resolution').desc().first()\n",
    "    stream.download(filename=output_path)\n",
    "    print(f\"‚úÖ Downloaded video to {output_path}\")\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3ebab-43b7-44c1-85aa-86752f2c6c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import json\n",
    "\n",
    "def find_interesting_segments(transcription_result):\n",
    "    text = transcription_result[\"text\"]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Given this transcription:\n",
    "\n",
    "{text}\n",
    "\n",
    "- Identify 3 of the most interesting moments (important sentences, funny moments, powerful messages).\n",
    "- For each moment, estimate a start time and end time (in seconds).\n",
    "- Provide a short description for each.\n",
    "\n",
    "Respond exactly in this JSON format:\n",
    "[\n",
    "  {{ \"start\": 15, \"end\": 30, \"text\": \"A touching story about friendship\" }},\n",
    "  {{ \"start\": 90, \"end\": 110, \"text\": \"Funny mistake during a trip\" }},\n",
    "  ...\n",
    "]\n",
    "Only output the JSON array, no extra explanation.\n",
    "    \"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='llama3',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        highlights = json.loads(response['message']['content'])\n",
    "        return highlights\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"‚ùå Error decoding highlights JSON.\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a85d128-c2db-4d44-a1ea-2a83824bb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "from moviepy import VideoFileClip\n",
    "import whisper\n",
    "import os\n",
    "import json\n",
    "import yt_dlp\n",
    "\n",
    "def download_video(video_url, output_path=\"videos\"):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]',\n",
    "        'outtmpl': f\"{output_path}/%(title)s.%(ext)s\",\n",
    "    }\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            info = ydl.extract_info(video_url, download=True)\n",
    "            return ydl.prepare_filename(info)\n",
    "    except Exception as e:\n",
    "        print(f\"Download failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_audio(video_path, audio_path=\"audio.wav\"):\n",
    "    try:\n",
    "        clip = VideoFileClip(video_path)\n",
    "        clip.audio.write_audiofile(audio_path)\n",
    "        return audio_path\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error extracting audio: {e}\")\n",
    "        return None\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    try:\n",
    "        model = whisper.load_model(\"small\")\n",
    "        result = model.transcribe(audio_path)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error transcribing audio: {e}\")\n",
    "        return None\n",
    "import ollama\n",
    "# These functions need to be defined or imported\n",
    "def find_interesting_segments(transcription_result):\n",
    "    text = transcription_result[\"text\"]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Given this transcription:\n",
    "\n",
    "{text}\n",
    "\n",
    "- Identify 3 of the most interesting moments (important sentences, funny moments, powerful messages).\n",
    "- For each moment, estimate a start time and end time (in seconds).\n",
    "- Provide a short description for each.\n",
    "\n",
    "Respond exactly in this JSON format:\n",
    "[\n",
    "  {{ \"start\": 15, \"end\": 30, \"text\": \"A touching story about friendship\" }},\n",
    "  {{ \"start\": 90, \"end\": 110, \"text\": \"Funny mistake during a trip\" }},\n",
    "  ...\n",
    "]\n",
    "Only output the JSON array, no extra explanation.\n",
    "    \"\"\"\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model='llama3',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        highlights = json.loads(response['message']['content'])\n",
    "        return highlights\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"‚ùå Error decoding highlights JSON.\")\n",
    "        return []\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "def cut_highlight(video_path, highlights, output_dir=\"highlights\"):\n",
    "    \"\"\"\n",
    "    Create highlight clips using FFmpeg (faster and more reliable than MoviePy)\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    created_clips = []\n",
    "    \n",
    "    for i, highlight in enumerate(highlights, 1):\n",
    "        output_path = os.path.join(output_dir, f\"highlight_{i}.mp4\")\n",
    "        \n",
    "        # Convert seconds to HH:MM:SS.microseconds\n",
    "        start_time = str(timedelta(seconds=highlight['start']))\n",
    "        end_time = str(timedelta(seconds=highlight['end']))\n",
    "        \n",
    "        try:\n",
    "            subprocess.run([\n",
    "                'ffmpeg',\n",
    "                '-y',  # Overwrite without asking\n",
    "                '-i', video_path,\n",
    "                '-ss', start_time,\n",
    "                '-to', end_time,\n",
    "                '-c:v', 'libx264',  # H.264 codec\n",
    "                '-c:a', 'aac',      # AAC audio\n",
    "                '-movflags', '+faststart',  # For web playback\n",
    "                '-loglevel', 'error',  # Only show errors\n",
    "                output_path\n",
    "            ], check=True)\n",
    "            \n",
    "            created_clips.append(output_path)\n",
    "            print(f\"‚úÖ Created highlight: {output_path}\")\n",
    "            \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"‚ùå Failed to create clip {i}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Unexpected error with clip {i}: {e}\")\n",
    "    \n",
    "    return created_clips\n",
    "\n",
    "def generate_title(text):\n",
    "    prompt = f\"\"\"\n",
    "Given this highlight text:\n",
    "\n",
    "{text}\n",
    "\n",
    "Generate a short, exciting YouTube short title using emojis and curiosity. Only return the title, no explanation.\n",
    "    \"\"\"\n",
    "    response = ollama.chat(\n",
    "        model='llama3',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response['message']['content'].strip()\n",
    "\n",
    "def main():\n",
    "    video_url = input(\"Paste YouTube URL here: \")\n",
    "    video_path = download_video(video_url)\n",
    "    \n",
    "    if not video_path:\n",
    "        return\n",
    "        \n",
    "    audio_path = extract_audio(video_path)\n",
    "    if not audio_path:\n",
    "        return\n",
    "        \n",
    "    transcription_result = transcribe_audio(audio_path)\n",
    "    if not transcription_result:\n",
    "        return\n",
    "\n",
    "    highlights = find_interesting_segments(transcription_result)\n",
    "\n",
    "    clips = cut_highlight(video_path, highlights)\n",
    "\n",
    "    print(\"\\n‚ú® Generated Titles:\")\n",
    "    for idx, highlight in enumerate(highlights):\n",
    "        title = generate_title(highlight['text'])\n",
    "        print(f\"  Clip {idx+1}: {title}\")\n",
    "\n",
    "    print(\"\\n‚úÖ Done! Check the 'highlights' folder for your clips.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbdcea1-4688-4821-888e-ea48e20a0f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import ollama\n",
    "from pytube import YouTube\n",
    "import whisper\n",
    "import random\n",
    "import textwrap\n",
    "import yt_dlp\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"output_dir\": \"output\",\n",
    "    \"font_path\": \"arial.ttf\",  # Replace with your font file\n",
    "    \"bg_music\": \"background.mp3\",  # Optional background music\n",
    "    \"ollama_model\": \"llama3\",  # Or \"mistral\"/\"phi3\"\n",
    "    \"whisper_model\": \"medium\",\n",
    "    \"target_resolution\": (1080, 1920)  # Shorts/Reels format\n",
    "}\n",
    "\n",
    "def setup_directories():\n",
    "    \"\"\"Create necessary folders\"\"\"\n",
    "    os.makedirs(CONFIG[\"output_dir\"], exist_ok=True)\n",
    "    os.makedirs(os.path.join(CONFIG[\"output_dir\"], \"clips\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(CONFIG[\"output_dir\"], \"assets\"), exist_ok=True)\n",
    "\n",
    "def download_video(video_url, output_path=\"videos\"):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]',\n",
    "        'outtmpl': f\"{output_path}/%(title)s.%(ext)s\",\n",
    "    }\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            info = ydl.extract_info(video_url, download=True)\n",
    "            return ydl.prepare_filename(info)\n",
    "    except Exception as e:\n",
    "        print(f\"Download failed: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_audio(video_path):\n",
    "    \"\"\"Extract high-quality audio for transcription\"\"\"\n",
    "    audio_path = os.path.join(CONFIG[\"output_dir\"], \"audio.wav\")\n",
    "    subprocess.run([\n",
    "        'ffmpeg', '-y', '-i', video_path,\n",
    "        '-vn', '-acodec', 'pcm_s16le',\n",
    "        '-ar', '44100', '-ac', '2',\n",
    "        '-loglevel', 'error',\n",
    "        audio_path\n",
    "    ], check=True)\n",
    "    return audio_path\n",
    "\n",
    "def transcribe_with_whisper(audio_path):\n",
    "    \"\"\"Transcribe with word-level timestamps\"\"\"\n",
    "    model = whisper.load_model(CONFIG[\"whisper_model\"])\n",
    "    result = model.transcribe(audio_path, word_timestamps=True)\n",
    "    return result\n",
    "\n",
    "\n",
    "def analyze_content(transcript):\n",
    "    \"\"\"Use Ollama to find highlights and generate metadata\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Analyze this transcript and identify 3-5 most engaging 8-15 second clips for Shorts/Reels.\n",
    "    Return JSON with list of highlights, each containing EXACTLY these keys:\n",
    "    - start (float): start time in seconds\n",
    "    - end (float): end time in seconds\n",
    "    - text (str): the spoken words\n",
    "    - reason (str): why this is engaging\n",
    "\n",
    "    Example:\n",
    "    {{\n",
    "        \"highlights\": [\n",
    "            {{\n",
    "                \"start\": 45.2,\n",
    "                \"end\": 53.7,\n",
    "                \"text\": \"This changed everything...\",\n",
    "                \"reason\": \"Emotional peak\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\n",
    "\n",
    "    Transcript:\n",
    "    {json.dumps(transcript['segments'], indent=2)}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = ollama.generate(\n",
    "            model=CONFIG[\"ollama_model\"],\n",
    "            prompt=prompt,\n",
    "            format=\"json\"\n",
    "        )\n",
    "        result = json.loads(response[\"response\"])\n",
    "        \n",
    "        # Extract highlights with validation\n",
    "        highlights = result.get('highlights', [])\n",
    "        if not isinstance(highlights, list):\n",
    "            highlights = [highlights] if isinstance(highlights, dict) else []\n",
    "        \n",
    "        # Validate each highlight\n",
    "        valid_highlights = []\n",
    "        for h in highlights:\n",
    "            if all(key in h for key in ['start', 'end', 'text', 'reason']):\n",
    "                valid_highlights.append({\n",
    "                    'start': float(h['start']),\n",
    "                    'end': float(h['end']),\n",
    "                    'text': str(h['text']),\n",
    "                    'reason': str(h['reason'])\n",
    "                })\n",
    "        \n",
    "        return valid_highlights or simple_highlight_detection(transcript)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è AI analysis failed: {e}\")\n",
    "        return simple_highlight_detection(transcript)\n",
    "\n",
    "\n",
    "def simple_highlight_detection(transcript):\n",
    "    \"\"\"Fallback that returns valid highlights\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            'start': max(0, s['start'] - 1),\n",
    "            'end': min(s['end'] + 1, transcript['segments'][-1]['end']),\n",
    "            'text': s.get('text', 'Interesting moment'),\n",
    "            'reason': \"Auto-selected segment\"\n",
    "        }\n",
    "        for s in transcript['segments'][:3]  # Take first 3 segments\n",
    "        if 'start' in s and 'end' in s\n",
    "    ]\n",
    "def create_vertical_clip(base_video, highlight, clip_num):\n",
    "    \"\"\"Generate Shorts/Reels with effects\"\"\"\n",
    "    output_path = os.path.join(CONFIG[\"output_dir\"], \"clips\", f\"clip_{clip_num}.mp4\")\n",
    "    temp_path = os.path.join(CONFIG[\"output_dir\"], \"clips\", f\"temp_{clip_num}.mp4\")\n",
    "    \n",
    "    # 1. Cut the clip with 0.5s padding\n",
    "    start = max(0, highlight['start'] - 0.5)\n",
    "    end = highlight['end'] + 0.5\n",
    "    \n",
    "    # 2. Create vertical crop with smart framing\n",
    "    subprocess.run([\n",
    "        'ffmpeg', '-y',\n",
    "        '-ss', str(start),\n",
    "        '-to', str(end),\n",
    "        '-i', base_video,\n",
    "        '-vf', f\"crop=ih*9/16:ih,scale={CONFIG['target_resolution'][0]}:{CONFIG['target_resolution'][1]},zoompan=z='min(zoom+0.0015,1.2)':d=1:x='if(gte(zoom,1.2),x,x+1)':y='y'\",\n",
    "        '-c:v', 'libx264', '-preset', 'fast', '-crf', '22',\n",
    "        '-an',  # Temporary remove audio\n",
    "        '-loglevel', 'error',\n",
    "        temp_path\n",
    "    ], check=True)\n",
    "    \n",
    "    # 3. Add dynamic subtitles\n",
    "    final_path = add_animated_subtitles(temp_path, highlight['text'], start, end)\n",
    "    \n",
    "    # 4. Mix with background music\n",
    "    return add_background_music(final_path, clip_num)\n",
    "\n",
    "def add_animated_subtitles(video_path, text, start, end):\n",
    "    \"\"\"Burn stylish animated subtitles into video\"\"\"\n",
    "    output_path = video_path.replace('.mp4', '_subtitled.mp4')\n",
    "    \n",
    "    # 1. Create temporary SRT file (more compatible than ASS)\n",
    "    srt_path = os.path.join(CONFIG[\"output_dir\"], \"subtitles.srt\")\n",
    "    with open(srt_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"1\\n{timedelta(seconds=0)} --> {timedelta(seconds=end-start)}\\n{text}\\n\")\n",
    "    \n",
    "    # 2. Generate subtitles with fallback options\n",
    "    try:\n",
    "        # Try with style first\n",
    "        subprocess.run([\n",
    "            'ffmpeg', '-y',\n",
    "            '-i', video_path,\n",
    "            '-vf', f\"subtitles='{srt_path}':force_style='FontName=Arial,FontSize=24,PrimaryColour=&HFFFFFF&,OutlineColour=&H000000&,Alignment=10'\",\n",
    "            '-c:v', 'libx264',\n",
    "            '-preset', 'fast',\n",
    "            '-crf', '22',\n",
    "            '-loglevel', 'error',\n",
    "            output_path\n",
    "        ], check=True, shell=True)\n",
    "    except subprocess.CalledProcessError:\n",
    "        # Fallback to simple subtitles\n",
    "        try:\n",
    "            subprocess.run([\n",
    "                'ffmpeg', '-y',\n",
    "                '-i', video_path,\n",
    "                '-vf', f\"drawtext=text='{text}':fontfile={CONFIG['font_path']}:fontsize=24:fontcolor=white:box=1:boxcolor=black@0.5:x=(w-text_w)/2:y=h-text_h-50\",\n",
    "                '-c:v', 'libx264',\n",
    "                '-preset', 'fast',\n",
    "                '-loglevel', 'error',\n",
    "                output_path\n",
    "            ], check=True, shell=True)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Subtitle fallback failed: {e}\")\n",
    "            return video_path  # Return original if all fails\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "def add_background_music(video_path, clip_num):\n",
    "    \"\"\"Mix with background music at low volume\"\"\"\n",
    "    if not os.path.exists(CONFIG[\"bg_music\"]):\n",
    "        return video_path  # Skip if no music\n",
    "    \n",
    "    final_path = video_path.replace('.mp4', '_final.mp4')\n",
    "    \n",
    "    subprocess.run([\n",
    "        'ffmpeg', '-y',\n",
    "        '-i', video_path,\n",
    "        '-i', CONFIG[\"bg_music\"],\n",
    "        '-filter_complex', '[0:a]volume=1.0[a0];[1:a]volume=0.3[a1];[a0][a1]amix=inputs=2:duration=shortest',\n",
    "        '-c:v', 'copy',\n",
    "        '-loglevel', 'error',\n",
    "        '-shortest',\n",
    "        final_path\n",
    "    ], check=True)\n",
    "    \n",
    "    return final_path\n",
    "\n",
    "def generate_social_metadata(highlight, clip_num):\n",
    "    \"\"\"Use Ollama to create engaging titles/hashtags\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Create social media metadata for this clip:\n",
    "    - 1 catchy title (emoji+power words)\n",
    "    - 5 relevant hashtags\n",
    "    - 1 call-to-action question\n",
    "    \n",
    "    Clip Content: \"{highlight['text']}\"\n",
    "    Engagement Reason: \"{highlight['reason']}\"\n",
    "    \n",
    "    Return JSON format:\n",
    "    {{\n",
    "        \"title\": \"...\",\n",
    "        \"hashtags\": [\"...\", \"...\"],\n",
    "        \"cta\": \"...\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    response = ollama.generate(\n",
    "        model=CONFIG[\"ollama_model\"],\n",
    "        prompt=prompt,\n",
    "        format=\"json\"\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        metadata = json.loads(response[\"response\"])\n",
    "    except:\n",
    "        metadata = {\n",
    "            \"title\": f\"üî• {highlight['text'][:50]}...\",\n",
    "            \"hashtags\": [\"#viral\", \"#trending\", \"#shorts\"],\n",
    "            \"cta\": \"What do you think?\"\n",
    "        }\n",
    "    \n",
    "    # Save metadata\n",
    "    with open(os.path.join(CONFIG[\"output_dir\"], \"clips\", f\"metadata_{clip_num}.json\"), 'w') as f:\n",
    "        json.dump(metadata, f)\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "\n",
    "def main(youtube_url):\n",
    "    setup_directories()\n",
    "    \n",
    "    print(\"‚è¨ Downloading video...\")\n",
    "    video_path = download_video(youtube_url)\n",
    "    if not video_path:\n",
    "        return\n",
    "    \n",
    "    print(\"üîä Extracting audio...\")\n",
    "    audio_path = extract_audio(video_path)\n",
    "    \n",
    "    print(\"üìù Transcribing content...\")\n",
    "    transcript = transcribe_with_whisper(audio_path)\n",
    "    \n",
    "    print(\"ü§ñ Analyzing for highlights...\")\n",
    "    highlights = analyze_content(transcript)\n",
    "    \n",
    "    print(\"üé¨ Creating Shorts/Reels...\")\n",
    "    for i, highlight in enumerate(highlights[:5]):\n",
    "        try:\n",
    "            print(f\"  Creating clip {i+1}: {highlight.get('text', 'Untitled')[:50]}...\")\n",
    "            clip_path = create_vertical_clip(video_path, highlight, i)\n",
    "            metadata = generate_social_metadata(highlight, i)\n",
    "            \n",
    "            print(f\"\"\"\n",
    "            ‚úÖ Clip {i+1} Complete!\n",
    "            Title: {metadata.get('title', 'Untitled')}\n",
    "            Hashtags: {' '.join(metadata.get('hashtags', ['#viral']))}\n",
    "            \"\"\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to process clip {i+1}: {e}\")\n",
    "    \n",
    "    print(f\"\\nüéâ Created {len(highlights[:5])} clips in {CONFIG['output_dir']}/clips\")\n",
    "if __name__ == \"__main__\":\n",
    "    youtube_url = input(\"Enter YouTube URL: \")\n",
    "    main(youtube_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
